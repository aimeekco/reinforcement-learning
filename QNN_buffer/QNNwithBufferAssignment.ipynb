{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install gymnasium"],"metadata":{"id":"KJUp6QBRY-Qd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738905476704,"user_tz":480,"elapsed":12391,"user":{"displayName":"Aimee Co","userId":"03856118716626959212"}},"outputId":"7e3ef311-cb58-4300-8afb-cc03d6edd81c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.0.0)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n"]}]},{"cell_type":"code","source":["from time import sleep\n","import numpy as np\n","from IPython.display import clear_output\n","import gymnasium as gym\n","from gymnasium.envs.registration import register\n","import torch\n","from torch import nn\n","import torch.optim as optim"],"metadata":{"id":"K_GLg7lbayhm","executionInfo":{"status":"ok","timestamp":1738905528592,"user_tz":480,"elapsed":4726,"user":{"displayName":"Aimee Co","userId":"03856118716626959212"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#Give colab access to your google drive:\n","from google.colab import drive\n","drive.mount('/gdrive')"],"metadata":{"id":"7PWN1PkGe66q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738905558825,"user_tz":480,"elapsed":17092,"user":{"displayName":"Aimee Co","userId":"03856118716626959212"}},"outputId":"d29cc476-02c8-4bf8-c93e-9c6ece88233c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","source":["#Change current directory to folder with MiniPacMan\n","%cd /gdrive/MyDrive/SP 25/Reinforcement Learning/Qnetwork"],"metadata":{"id":"1SCX1d90YjOg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738905561099,"user_tz":480,"elapsed":176,"user":{"displayName":"Aimee Co","userId":"03856118716626959212"}},"outputId":"021b7b98-2879-49d0-a9bb-3207ee610c71"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/gdrive/MyDrive/SP 25/Reinforcement Learning/Qnetwork\n"]}]},{"cell_type":"code","source":["#Import MiniPacMan environment class definition\n","from MiniPacManGym import MiniPacManEnv"],"metadata":{"id":"GCa5TYdVWL2y","executionInfo":{"status":"ok","timestamp":1738905562664,"user_tz":480,"elapsed":563,"user":{"displayName":"Aimee Co","userId":"03856118716626959212"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#Register MiniPacMan in your gymnasium environments\n","register(\n","    id=\"MiniPacMan-v0\",\n","    entry_point=MiniPacManEnv,  # Update with your actual module path\n","    max_episode_steps=20          # You can also set a default here\n",")"],"metadata":{"id":"TcY1Q97RRy6J","executionInfo":{"status":"ok","timestamp":1738905564228,"user_tz":480,"elapsed":6,"user":{"displayName":"Aimee Co","userId":"03856118716626959212"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#Create a MiniPacMan gymnasium environment\n","env = gym.make(\"MiniPacMan-v0\", render_mode=\"human\", frozen_ghost=False)"],"metadata":{"id":"k7hwnC7Ob9VJ","executionInfo":{"status":"ok","timestamp":1738905573507,"user_tz":480,"elapsed":1,"user":{"displayName":"Aimee Co","userId":"03856118716626959212"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class QNetwork(nn.Module):\n","    def __init__(self):\n","      super().__init__()\n","      self.flatten = nn.Flatten()\n","      self.linear1 = nn.Linear(6 * 6, 64)\n","      self.activation = nn.ReLU()\n","      self.linear2 = nn.Linear(64, 4)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.linear1(x)\n","        x = self.activation(x)\n","        x = self.linear2(x)\n","        return x"],"metadata":{"id":"Y6irumLQsc1p","executionInfo":{"status":"ok","timestamp":1738905889124,"user_tz":480,"elapsed":92,"user":{"displayName":"Aimee Co","userId":"03856118716626959212"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["class ReplayBuffer:\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.buffer = []\n","\n","    def push(self, state, action, reward, next_state, done):\n","        if len(self.buffer) >= self.capacity:\n","            self.buffer.pop(0)\n","        self.buffer.append((state, action, reward, next_state, done))\n","\n","    def sample(self, batch_size):\n","        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n","        states, actions, rewards, next_states, dones = zip(*[self.buffer[i] for i in indices])\n","        return torch.stack(states), actions, torch.tensor(rewards), torch.stack(next_states), torch.tensor(dones)"],"metadata":{"id":"8D31lBLpRUC0","executionInfo":{"status":"ok","timestamp":1738905895939,"user_tz":480,"elapsed":1,"user":{"displayName":"Aimee Co","userId":"03856118716626959212"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["q_network = QNetwork()\n","optimizer = optim.Adam(q_network.parameters(), lr=0.001)\n","loss_fn = nn.MSELoss()"],"metadata":{"id":"6-TgasGh9Q11","executionInfo":{"status":"ok","timestamp":1738905899493,"user_tz":480,"elapsed":2,"user":{"displayName":"Aimee Co","userId":"03856118716626959212"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["#set hyperparams -- play with any of these!\n","gamma=0.95\n","buffer_size=1000\n","batch_size=32\n","num_episodes=10000\n","\n","RB=ReplayBuffer(buffer_size) #initialize Replay Buffer\n","epsilon=1 #initialize epsilon\n","\n","for e in range(num_episodes):\n","  new_obs,info=env.reset()\n","  new_obs=torch.tensor(new_obs,dtype=torch.float32).unsqueeze(0)\n","\n","  done=False\n","  truncated=False\n","  steps=0\n","\n","  while not done and not truncated: #Loop for one episode\n","    obs=new_obs\n","\n","    #choose action\n","    t=np.random.random()\n","    if t>epsilon:\n","      with torch.no_grad():\n","        action=torch.argmax(q_network(obs)).item() #exploitation\n","    else:\n","      # action=torch.randint(4,(1,)).item()\n","      action= env.action_space.sample()\n","\n","    #take a step:\n","    new_obs,reward, done, truncated, info=env.step(action)\n","    new_obs=torch.tensor(new_obs,dtype=torch.float32).unsqueeze(0)\n","    RB.push(obs,action,reward,new_obs,done)\n","    steps+=1\n","\n","    if len(RB.buffer)>=batch_size:\n","      states, actions, rewards, next_states, dones=RB.sample(batch_size)\n","\n","    #compute target q-value\n","    with torch.no_grad():\n","      reward_tensor = torch.tensor(reward, dtype=torch.float32)\n","      if done:\n","          target_q = reward_tensor\n","      else:\n","          target_q = reward_tensor + gamma * torch.max(q_network(new_obs))\n","\n","    #current q-value\n","    # q_values = q_network(obs).squeeze(0)\n","    # current_q = q_values[action]\n","    current_q = q_network(obs)[0, action]\n","\n","    #compute loss\n","    loss = loss_fn(current_q, target_q)\n","\n","    #Q-network update rule:\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","  #reduce episilon if its not too low:\n","  epsilon=max(0.01, epsilon - 1.0/num_episodes)\n","\n","  #periodic reporting:\n","  if e>0 and e%100==0:\n","    print(f'episode: {e}, steps: {steps}, epsilon: {epsilon},win: {reward==10}')\n"],"metadata":{"id":"0fe-YvvwKpAZ","collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738906211579,"user_tz":480,"elapsed":73975,"user":{"displayName":"Aimee Co","userId":"03856118716626959212"}},"outputId":"6e913bf6-886e-40e7-b5fb-ae3a22db15ab"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["episode: 100, steps: 1, epsilon: 0.9899000000000011,win: False\n","episode: 200, steps: 3, epsilon: 0.9799000000000022,win: False\n","episode: 300, steps: 1, epsilon: 0.9699000000000033,win: False\n","episode: 400, steps: 1, epsilon: 0.9599000000000044,win: False\n","episode: 500, steps: 13, epsilon: 0.9499000000000055,win: False\n","episode: 600, steps: 1, epsilon: 0.9399000000000066,win: False\n","episode: 700, steps: 1, epsilon: 0.9299000000000077,win: False\n","episode: 800, steps: 1, epsilon: 0.9199000000000088,win: False\n","episode: 900, steps: 2, epsilon: 0.9099000000000099,win: False\n","episode: 1000, steps: 1, epsilon: 0.899900000000011,win: False\n","episode: 1100, steps: 3, epsilon: 0.8899000000000121,win: False\n","episode: 1200, steps: 1, epsilon: 0.8799000000000132,win: False\n","episode: 1300, steps: 1, epsilon: 0.8699000000000143,win: False\n","episode: 1400, steps: 3, epsilon: 0.8599000000000154,win: False\n","episode: 1500, steps: 1, epsilon: 0.8499000000000165,win: False\n","episode: 1600, steps: 1, epsilon: 0.8399000000000176,win: False\n","episode: 1700, steps: 1, epsilon: 0.8299000000000187,win: False\n","episode: 1800, steps: 2, epsilon: 0.8199000000000198,win: False\n","episode: 1900, steps: 1, epsilon: 0.8099000000000209,win: False\n","episode: 2000, steps: 1, epsilon: 0.799900000000022,win: False\n","episode: 2100, steps: 3, epsilon: 0.7899000000000231,win: False\n","episode: 2200, steps: 2, epsilon: 0.7799000000000242,win: False\n","episode: 2300, steps: 1, epsilon: 0.7699000000000253,win: False\n","episode: 2400, steps: 8, epsilon: 0.7599000000000264,win: False\n","episode: 2500, steps: 1, epsilon: 0.7499000000000275,win: False\n","episode: 2600, steps: 1, epsilon: 0.7399000000000286,win: False\n","episode: 2700, steps: 1, epsilon: 0.7299000000000297,win: False\n","episode: 2800, steps: 1, epsilon: 0.7199000000000308,win: False\n","episode: 2900, steps: 2, epsilon: 0.709900000000032,win: False\n","episode: 3000, steps: 3, epsilon: 0.699900000000033,win: False\n","episode: 3100, steps: 3, epsilon: 0.6899000000000342,win: False\n","episode: 3200, steps: 1, epsilon: 0.6799000000000353,win: False\n","episode: 3300, steps: 2, epsilon: 0.6699000000000364,win: False\n","episode: 3400, steps: 1, epsilon: 0.6599000000000375,win: False\n","episode: 3500, steps: 1, epsilon: 0.6499000000000386,win: False\n","episode: 3600, steps: 3, epsilon: 0.6399000000000397,win: False\n","episode: 3700, steps: 1, epsilon: 0.6299000000000408,win: False\n","episode: 3800, steps: 4, epsilon: 0.6199000000000419,win: False\n","episode: 3900, steps: 2, epsilon: 0.609900000000043,win: False\n","episode: 4000, steps: 1, epsilon: 0.5999000000000441,win: False\n","episode: 4100, steps: 1, epsilon: 0.5899000000000452,win: False\n","episode: 4200, steps: 6, epsilon: 0.5799000000000463,win: False\n","episode: 4300, steps: 2, epsilon: 0.5699000000000474,win: False\n","episode: 4400, steps: 6, epsilon: 0.5599000000000485,win: False\n","episode: 4500, steps: 2, epsilon: 0.5499000000000496,win: False\n","episode: 4600, steps: 3, epsilon: 0.5399000000000507,win: False\n","episode: 4700, steps: 4, epsilon: 0.5299000000000518,win: False\n","episode: 4800, steps: 2, epsilon: 0.5199000000000529,win: False\n","episode: 4900, steps: 6, epsilon: 0.509900000000054,win: True\n","episode: 5000, steps: 7, epsilon: 0.4999000000000551,win: False\n","episode: 5100, steps: 6, epsilon: 0.4899000000000562,win: True\n","episode: 5200, steps: 7, epsilon: 0.4799000000000573,win: False\n","episode: 5300, steps: 14, epsilon: 0.4699000000000584,win: True\n","episode: 5400, steps: 4, epsilon: 0.4599000000000595,win: False\n","episode: 5500, steps: 1, epsilon: 0.4499000000000606,win: False\n","episode: 5600, steps: 2, epsilon: 0.4399000000000617,win: False\n","episode: 5700, steps: 2, epsilon: 0.4299000000000628,win: False\n","episode: 5800, steps: 8, epsilon: 0.4199000000000639,win: True\n","episode: 5900, steps: 6, epsilon: 0.409900000000065,win: True\n","episode: 6000, steps: 1, epsilon: 0.3999000000000661,win: False\n","episode: 6100, steps: 3, epsilon: 0.3899000000000672,win: False\n","episode: 6200, steps: 6, epsilon: 0.3799000000000683,win: False\n","episode: 6300, steps: 2, epsilon: 0.3699000000000694,win: False\n","episode: 6400, steps: 6, epsilon: 0.3599000000000705,win: False\n","episode: 6500, steps: 1, epsilon: 0.3499000000000716,win: False\n","episode: 6600, steps: 2, epsilon: 0.3399000000000727,win: False\n","episode: 6700, steps: 3, epsilon: 0.3299000000000738,win: False\n","episode: 6800, steps: 6, epsilon: 0.3199000000000749,win: False\n","episode: 6900, steps: 2, epsilon: 0.309900000000076,win: False\n","episode: 7000, steps: 4, epsilon: 0.2999000000000771,win: False\n","episode: 7100, steps: 6, epsilon: 0.2899000000000782,win: False\n","episode: 7200, steps: 6, epsilon: 0.2799000000000793,win: True\n","episode: 7300, steps: 7, epsilon: 0.2699000000000804,win: False\n","episode: 7400, steps: 2, epsilon: 0.2599000000000815,win: False\n","episode: 7500, steps: 4, epsilon: 0.2499000000000826,win: False\n","episode: 7600, steps: 3, epsilon: 0.2399000000000837,win: False\n","episode: 7700, steps: 5, epsilon: 0.22990000000008481,win: False\n","episode: 7800, steps: 6, epsilon: 0.21990000000008592,win: False\n","episode: 7900, steps: 6, epsilon: 0.20990000000008702,win: True\n","episode: 8000, steps: 6, epsilon: 0.19990000000008812,win: False\n","episode: 8100, steps: 3, epsilon: 0.18990000000008922,win: False\n","episode: 8200, steps: 3, epsilon: 0.17990000000009032,win: False\n","episode: 8300, steps: 8, epsilon: 0.16990000000009142,win: True\n","episode: 8400, steps: 6, epsilon: 0.15990000000009252,win: True\n","episode: 8500, steps: 10, epsilon: 0.14990000000009363,win: True\n","episode: 8600, steps: 6, epsilon: 0.13990000000009473,win: True\n","episode: 8700, steps: 8, epsilon: 0.12990000000009583,win: True\n","episode: 8800, steps: 6, epsilon: 0.11990000000009622,win: True\n","episode: 8900, steps: 8, epsilon: 0.10990000000009593,win: True\n","episode: 9000, steps: 2, epsilon: 0.09990000000009565,win: False\n","episode: 9100, steps: 8, epsilon: 0.08990000000009536,win: True\n","episode: 9200, steps: 6, epsilon: 0.07990000000009508,win: True\n","episode: 9300, steps: 6, epsilon: 0.06990000000009479,win: True\n","episode: 9400, steps: 6, epsilon: 0.0599000000000945,win: True\n","episode: 9500, steps: 6, epsilon: 0.049900000000094216,win: True\n","episode: 9600, steps: 6, epsilon: 0.03990000000009393,win: True\n","episode: 9700, steps: 7, epsilon: 0.029900000000093692,win: False\n","episode: 9800, steps: 8, epsilon: 0.019900000000093752,win: True\n","episode: 9900, steps: 6, epsilon: 0.01,win: True\n"]}]},{"cell_type":"code","source":["obs, info = env.reset()\n","done = False\n","truncated = False\n","\n","while not done and not truncated:\n","    env.render()\n","    obs=torch.tensor(obs,dtype=torch.float32).unsqueeze(0)\n","    with torch.no_grad():\n","        action = torch.argmax(q_network(obs)).item()\n","    obs, reward, done, truncated, info = env.step(action)\n","    sleep(1)\n","    clear_output(wait=True)\n","\n","env.render()\n","env.close()"],"metadata":{"id":"0SXyI97eNx6L","colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"status":"error","timestamp":1738955231511,"user_tz":480,"elapsed":246,"user":{"displayName":"Aimee Co","userId":"03856118716626959212"}},"outputId":"05a67d3a-b215-487b-9b89-3fc9415c7547"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'env' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-c6cbbf79d93b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtruncated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"]}]}]}
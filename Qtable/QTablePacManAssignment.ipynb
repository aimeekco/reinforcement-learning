{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aimeekco/reinforcement-learning/blob/main/QTablePacManAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gymnasium"
      ],
      "metadata": {
        "id": "KJUp6QBRY-Qd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4278694-6981-45bd-ce01-102aadc8c7d9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "import gymnasium as gym\n",
        "from gymnasium.envs.registration import register"
      ],
      "metadata": {
        "id": "K_GLg7lbayhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Give colab access to your google drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "7PWN1PkGe66q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1c7e5a-e380-49cc-bd3d-a38022ba0044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Change current directory to folder with MiniPacManGym.py\n",
        "%cd /gdrive/MyDrive/SP 25/Reinforcement Learning/PacMan"
      ],
      "metadata": {
        "id": "1SCX1d90YjOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e9342d-41de-4bcf-c3ce-c9f3c7e606ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/SP 25/Reinforcement Learning/PacMan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import MiniPacMan environment class definition\n",
        "from MiniPacManGym import MiniPacManEnv"
      ],
      "metadata": {
        "id": "GCa5TYdVWL2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Register MiniPacMan in your gymnasium environments\n",
        "register(\n",
        "    id=\"MiniPacMan-v0\",\n",
        "    entry_point=MiniPacManEnv,\n",
        "    max_episode_steps=20\n",
        ")"
      ],
      "metadata": {
        "id": "TcY1Q97RRy6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a MiniPacMan gymnasium environment\n",
        "env = gym.make(\"MiniPacMan-v0\", render_mode=\"human\", frozen_ghost=True)"
      ],
      "metadata": {
        "id": "k7hwnC7Ob9VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set hyperparams -- feel free to play with these!\n",
        "gamma=0.999\n",
        "alpha=0.9\n",
        "num_episodes=10000\n",
        "\n",
        "#initialize epsilon, Q\n",
        "epsilon=1\n",
        "Q=np.zeros((6,6,4)) #First two coordinates encode state, last encodes action\n",
        "\n",
        "for e in range(num_episodes):\n",
        "  new_obs,info=env.reset()\n",
        "  new_pos=np.argwhere(new_obs==1)[0] #current pacman position\n",
        "  done=False\n",
        "  truncated=False\n",
        "  steps=0\n",
        "\n",
        "  while not done and not truncated: #Loop for one episode\n",
        "    obs=new_obs\n",
        "    pos=new_pos\n",
        "\n",
        "    #choose action\n",
        "    t=np.random.random()\n",
        "    if t>epsilon:\n",
        "      action= np.argmax(Q[pos[0], pos[1], :])\n",
        "    else:\n",
        "      action= env.action_space.sample()\n",
        "\n",
        "    #take a step:\n",
        "    new_obs,reward, done, truncated, info=env.step(action)\n",
        "    steps+=1\n",
        "    new_pos=np.argwhere(new_obs==1)[0] #next pacman position\n",
        "\n",
        "    #Q-table update rule:\n",
        "    Q[pos[0],pos[1],action]= Q[pos[0], pos[1], action] + alpha * (reward + gamma * np.max(Q[new_pos[0], new_pos[1], :]) - Q[pos[0], pos[1], action])\n",
        "\n",
        "  #reduce episilon if its not too low\n",
        "  #Should be close to zero after 50 - 60% of episodes, and then level off\n",
        "  epsilon= max(0.01, epsilon - 1.0 / num_episodes)\n",
        "\n",
        "  #periodic reporting:\n",
        "  if e%100==0:\n",
        "    print(f'episode: {e}, steps: {steps}, epislon: {epsilon}, win: {reward==10}')\n"
      ],
      "metadata": {
        "id": "0fe-YvvwKpAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f67726-ffb7-4776-832a-7e470ed43fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 0, steps: 1, epislon: 0.9999, win: False\n",
            "episode: 100, steps: 1, epislon: 0.9899000000000011, win: False\n",
            "episode: 200, steps: 2, epislon: 0.9799000000000022, win: False\n",
            "episode: 300, steps: 1, epislon: 0.9699000000000033, win: False\n",
            "episode: 400, steps: 1, epislon: 0.9599000000000044, win: False\n",
            "episode: 500, steps: 3, epislon: 0.9499000000000055, win: False\n",
            "episode: 600, steps: 7, epislon: 0.9399000000000066, win: False\n",
            "episode: 700, steps: 3, epislon: 0.9299000000000077, win: False\n",
            "episode: 800, steps: 1, epislon: 0.9199000000000088, win: False\n",
            "episode: 900, steps: 8, epislon: 0.9099000000000099, win: False\n",
            "episode: 1000, steps: 5, epislon: 0.899900000000011, win: False\n",
            "episode: 1100, steps: 4, epislon: 0.8899000000000121, win: False\n",
            "episode: 1200, steps: 2, epislon: 0.8799000000000132, win: False\n",
            "episode: 1300, steps: 1, epislon: 0.8699000000000143, win: False\n",
            "episode: 1400, steps: 1, epislon: 0.8599000000000154, win: False\n",
            "episode: 1500, steps: 2, epislon: 0.8499000000000165, win: False\n",
            "episode: 1600, steps: 4, epislon: 0.8399000000000176, win: False\n",
            "episode: 1700, steps: 9, epislon: 0.8299000000000187, win: False\n",
            "episode: 1800, steps: 3, epislon: 0.8199000000000198, win: False\n",
            "episode: 1900, steps: 1, epislon: 0.8099000000000209, win: False\n",
            "episode: 2000, steps: 1, epislon: 0.799900000000022, win: False\n",
            "episode: 2100, steps: 5, epislon: 0.7899000000000231, win: False\n",
            "episode: 2200, steps: 5, epislon: 0.7799000000000242, win: False\n",
            "episode: 2300, steps: 1, epislon: 0.7699000000000253, win: False\n",
            "episode: 2400, steps: 6, epislon: 0.7599000000000264, win: True\n",
            "episode: 2500, steps: 1, epislon: 0.7499000000000275, win: False\n",
            "episode: 2600, steps: 2, epislon: 0.7399000000000286, win: False\n",
            "episode: 2700, steps: 2, epislon: 0.7299000000000297, win: False\n",
            "episode: 2800, steps: 12, epislon: 0.7199000000000308, win: True\n",
            "episode: 2900, steps: 1, epislon: 0.709900000000032, win: False\n",
            "episode: 3000, steps: 1, epislon: 0.699900000000033, win: False\n",
            "episode: 3100, steps: 1, epislon: 0.6899000000000342, win: False\n",
            "episode: 3200, steps: 3, epislon: 0.6799000000000353, win: False\n",
            "episode: 3300, steps: 5, epislon: 0.6699000000000364, win: False\n",
            "episode: 3400, steps: 3, epislon: 0.6599000000000375, win: False\n",
            "episode: 3500, steps: 4, epislon: 0.6499000000000386, win: False\n",
            "episode: 3600, steps: 1, epislon: 0.6399000000000397, win: False\n",
            "episode: 3700, steps: 8, epislon: 0.6299000000000408, win: False\n",
            "episode: 3800, steps: 1, epislon: 0.6199000000000419, win: False\n",
            "episode: 3900, steps: 1, epislon: 0.609900000000043, win: False\n",
            "episode: 4000, steps: 1, epislon: 0.5999000000000441, win: False\n",
            "episode: 4100, steps: 3, epislon: 0.5899000000000452, win: False\n",
            "episode: 4200, steps: 1, epislon: 0.5799000000000463, win: False\n",
            "episode: 4300, steps: 1, epislon: 0.5699000000000474, win: False\n",
            "episode: 4400, steps: 6, epislon: 0.5599000000000485, win: True\n",
            "episode: 4500, steps: 10, epislon: 0.5499000000000496, win: False\n",
            "episode: 4600, steps: 6, epislon: 0.5399000000000507, win: False\n",
            "episode: 4700, steps: 3, epislon: 0.5299000000000518, win: False\n",
            "episode: 4800, steps: 8, epislon: 0.5199000000000529, win: False\n",
            "episode: 4900, steps: 2, epislon: 0.509900000000054, win: False\n",
            "episode: 5000, steps: 12, epislon: 0.4999000000000551, win: True\n",
            "episode: 5100, steps: 12, epislon: 0.4899000000000562, win: True\n",
            "episode: 5200, steps: 6, epislon: 0.4799000000000573, win: True\n",
            "episode: 5300, steps: 3, epislon: 0.4699000000000584, win: False\n",
            "episode: 5400, steps: 12, epislon: 0.4599000000000595, win: True\n",
            "episode: 5500, steps: 1, epislon: 0.4499000000000606, win: False\n",
            "episode: 5600, steps: 6, epislon: 0.4399000000000617, win: True\n",
            "episode: 5700, steps: 3, epislon: 0.4299000000000628, win: False\n",
            "episode: 5800, steps: 3, epislon: 0.4199000000000639, win: False\n",
            "episode: 5900, steps: 4, epislon: 0.409900000000065, win: False\n",
            "episode: 6000, steps: 1, epislon: 0.3999000000000661, win: False\n",
            "episode: 6100, steps: 4, epislon: 0.3899000000000672, win: False\n",
            "episode: 6200, steps: 1, epislon: 0.3799000000000683, win: False\n",
            "episode: 6300, steps: 8, epislon: 0.3699000000000694, win: True\n",
            "episode: 6400, steps: 2, epislon: 0.3599000000000705, win: False\n",
            "episode: 6500, steps: 8, epislon: 0.3499000000000716, win: True\n",
            "episode: 6600, steps: 10, epislon: 0.3399000000000727, win: True\n",
            "episode: 6700, steps: 3, epislon: 0.3299000000000738, win: False\n",
            "episode: 6800, steps: 4, epislon: 0.3199000000000749, win: False\n",
            "episode: 6900, steps: 10, epislon: 0.309900000000076, win: True\n",
            "episode: 7000, steps: 3, epislon: 0.2999000000000771, win: False\n",
            "episode: 7100, steps: 6, epislon: 0.2899000000000782, win: True\n",
            "episode: 7200, steps: 6, epislon: 0.2799000000000793, win: False\n",
            "episode: 7300, steps: 8, epislon: 0.2699000000000804, win: True\n",
            "episode: 7400, steps: 8, epislon: 0.2599000000000815, win: True\n",
            "episode: 7500, steps: 6, epislon: 0.2499000000000826, win: True\n",
            "episode: 7600, steps: 1, epislon: 0.2399000000000837, win: False\n",
            "episode: 7700, steps: 6, epislon: 0.22990000000008481, win: True\n",
            "episode: 7800, steps: 6, epislon: 0.21990000000008592, win: True\n",
            "episode: 7900, steps: 6, epislon: 0.20990000000008702, win: True\n",
            "episode: 8000, steps: 6, epislon: 0.19990000000008812, win: True\n",
            "episode: 8100, steps: 8, epislon: 0.18990000000008922, win: True\n",
            "episode: 8200, steps: 2, epislon: 0.17990000000009032, win: False\n",
            "episode: 8300, steps: 10, epislon: 0.16990000000009142, win: True\n",
            "episode: 8400, steps: 6, epislon: 0.15990000000009252, win: True\n",
            "episode: 8500, steps: 6, epislon: 0.14990000000009363, win: True\n",
            "episode: 8600, steps: 5, epislon: 0.13990000000009473, win: False\n",
            "episode: 8700, steps: 3, epislon: 0.12990000000009583, win: False\n",
            "episode: 8800, steps: 8, epislon: 0.11990000000009622, win: True\n",
            "episode: 8900, steps: 6, epislon: 0.10990000000009593, win: True\n",
            "episode: 9000, steps: 8, epislon: 0.09990000000009565, win: True\n",
            "episode: 9100, steps: 2, epislon: 0.08990000000009536, win: False\n",
            "episode: 9200, steps: 6, epislon: 0.07990000000009508, win: True\n",
            "episode: 9300, steps: 6, epislon: 0.06990000000009479, win: True\n",
            "episode: 9400, steps: 8, epislon: 0.0599000000000945, win: True\n",
            "episode: 9500, steps: 8, epislon: 0.049900000000094216, win: True\n",
            "episode: 9600, steps: 6, epislon: 0.03990000000009393, win: True\n",
            "episode: 9700, steps: 6, epislon: 0.029900000000093692, win: True\n",
            "episode: 9800, steps: 6, epislon: 0.019900000000093752, win: True\n",
            "episode: 9900, steps: 6, epislon: 0.01, win: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this code cell to see your trained agent in action!\n",
        "\n",
        "obs, info = env.reset()\n",
        "done = False\n",
        "truncated = False\n",
        "\n",
        "while not done and not truncated:\n",
        "    env.render()\n",
        "    pos= np.argwhere(obs == 1)[0]   #pacman position\n",
        "    action= np.argmax(Q[pos[0], pos[1], :])\n",
        "    obs, reward, done, truncated, info = env.step(action)\n",
        "    sleep(1)\n",
        "    clear_output(wait=True)\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "id": "0SXyI97eNx6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b770c3b5-7419-4424-bcac-aea6cefb5f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xxxxxx\n",
            "x····x\n",
            "x··ᗣ·x\n",
            "x····x\n",
            "x··ᗧ◯x\n",
            "xxxxxx\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VZjO1S_URYs2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}